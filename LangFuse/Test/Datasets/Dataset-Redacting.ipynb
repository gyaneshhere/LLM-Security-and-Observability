{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b45cf4ae-9e61-4889-b169-f293002556a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b468597b-1aed-4df5-a2cd-16b79d5b419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import openai\n",
    "from langfuse.decorators import observe\n",
    " \n",
    "@observe()\n",
    "def openai_fn(calc: str):\n",
    "    res = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a very accurate calculator. You output only the result of the calculation.\"},\n",
    "          {\"role\": \"user\", \"content\": calc}],\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddd2acfe-54d7-4d76-ac9e-b0acd6806246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    " \n",
    "doc1 = Document(text=\"\"\"\n",
    "Maxwell \"Max\" Silverstein, a lauded movie director, screenwriter, and producer, was born on October 25, 1978, in Boston, Massachusetts. A film enthusiast from a young age, his journey began with home movies shot on a Super 8 camera. His passion led him to the University of Southern California (USC), majoring in Film Production. Eventually, he started his career as an assistant director at Paramount Pictures. Silverstein's directorial debut, “Doors Unseen,” a psychological thriller, earned him recognition at the Sundance Film Festival and marked the beginning of a successful directing career.\n",
    "\"\"\")\n",
    "doc2 = Document(text=\"\"\"\n",
    "Throughout his career, Silverstein has been celebrated for his diverse range of filmography and unique narrative technique. He masterfully blends suspense, human emotion, and subtle humor in his storylines. Among his notable works are \"Fleeting Echoes,\" \"Halcyon Dusk,\" and the Academy Award-winning sci-fi epic, \"Event Horizon's Brink.\" His contribution to cinema revolves around examining human nature, the complexity of relationships, and probing reality and perception. Off-camera, he is a dedicated philanthropist living in Los Angeles with his wife and two children.\n",
    "\"\"\")\n",
    " \n",
    "@observe()\n",
    "def llama_index_fn(question: str):\n",
    "    # Set callback manager for LlamaIndex, will apply to all LlamaIndex executions in this function\n",
    "    langfuse_handler = langfuse_context.get_current_llama_index_handler()\n",
    "    Settings.callback_manager = CallbackManager([langfuse_handler])\n",
    " \n",
    "    # Run application\n",
    "    index = VectorStoreIndex.from_documents([doc1,doc2])\n",
    "    response = index.as_query_engine().query(question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "005c5f57-549f-45ba-a28b-21eb8aaa6b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langfuse.decorators import observe\n",
    " \n",
    "prompt = ChatPromptTemplate.from_template(\"what is the city {person} is from?\")\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model | StrOutputParser()\n",
    " \n",
    "@observe()\n",
    "def langchain_fn(person: str):\n",
    "    # Get Langchain Callback Handler scoped to the current trace context\n",
    "    langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    " \n",
    "    # Pass handler to invoke\n",
    "    chain.invoke({\"person\": person}, config={\"callbacks\":[langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccf9c165-bb38-4bc0-bc27-0182c3ca8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72c682da-32bf-41d1-984f-7645ebdde264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Neil Armstrong stepped out of the lunar module Eagle onto the moon's surface on July 20, 1969, his famous first words were: \"That's one small step for man, one giant leap for mankind.\"\n"
     ]
    }
   ],
   "source": [
    "# Drop-in replacement to get full logging by changing only the import\n",
    "from langfuse.openai import OpenAI\n",
    " \n",
    "# Configure the OpenAI client to use http://localhost:11434/v1 as base url \n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    ")\n",
    " \n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama3\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first person to step on the moon?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Neil Armstrong was the first person to step on the moon on July 20, 1969, during the Apollo 11 mission.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What were his first words when he stepped on the moon?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "765e8905-c8d9-4149-a2fd-a207f06a1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context\n",
    "langfuse_context.flush()\n",
    " \n",
    "# low-level SDK\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed8e4e9c-89ff-4905-9c67-4a5fdebc1ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there existed a mystical planet known as Lumina, where magic thrived and ancient prophecies foretold of a great hero who would save the planet from impending darkness. The inhabitants of Lumina were diverse beings with powers beyond imagination, from shape-shifting dragons to telepathic elves.\\n\\nDeep within the enchanted forests of Lumina, a young sorcerer named Ember discovered a mysterious amulet that glowed with a brilliant light. Little did she know that this amulet held the key to unlocking'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse.decorators import observe\n",
    "from langfuse.openai import openai # OpenAI integration\n",
    " \n",
    "@observe()\n",
    "def story():\n",
    "    return openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=100,\n",
    "        messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a great storyteller.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Once upon a time in a galaxy far, far away...\"}\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    " \n",
    "@observe()\n",
    "def main():\n",
    "    return story()\n",
    " \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6fe5a7b-6c94-410c-a146-53c71a2d8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import openai\n",
    " \n",
    "completion = openai.chat.completions.create(\n",
    "  name=\"test-chat\",\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a calculator.\"},\n",
    "    {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
    "  temperature=0,\n",
    " \n",
    "  # add session_id as additional argument\n",
    "  session_id=\"gy12345\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3ef870f-ce7c-4a39-8973-30bbea00056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "from langfuse.openai import openai\n",
    " \n",
    "@observe()\n",
    "def fn():\n",
    "    langfuse_context.update_current_trace(\n",
    "        session_id=\"gy12345\"\n",
    "    )\n",
    " \n",
    "    completion = openai.chat.completions.create(\n",
    "      name=\"test-chat\",\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a calculator.\"},\n",
    "        {\"role\": \"user\", \"content\": \"1 + 1 = \"}],\n",
    "      temperature=0,\n",
    "    )\n",
    " \n",
    "fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "574831d1-8ab0-497d-94cc-6fb2110d60e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.client.StatefulSpanClient at 0x10c5ab3e0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    " \n",
    "trace = langfuse.trace()\n",
    " \n",
    "# Add an observation (span) with a level and status message\n",
    "trace.span(\n",
    "    level=\"WARNING\",\n",
    "    status_message=\"This is a warning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4caaeaf-d360-41e8-a532-dd01cb340f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of: import openai\n",
    "from langfuse.openai import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c6b0baa-f3ea-4a77-9967-6d9f2d0086bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = langfuse.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7512d4fc-4d9a-440f-94e6-a501515fb5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.client.StatefulSpanClient at 0x10c5cf920>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    " \n",
    "trace = langfuse.trace()\n",
    " \n",
    "# Add an observation (span) with a level and status message\n",
    "trace.span(\n",
    "    level=\"WARNING\",\n",
    "    status_message=response.choices[0].message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3fa4d1b-058d-40e8-9959-6e43a95168c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context\n",
    "langfuse_context.flush()\n",
    " \n",
    "# low-level SDK\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99a0a8aa-0c29-4659-8bb7-bf538a3a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0490c0d3-d68c-4c2e-b91e-cd59ad889143",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fd4136f-64a4-46b9-a2c1-668e09c67eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There existed a planet known as Auroria, a place filled with lush forests, majestic mountains, and shimmering crystal lakes. The inhabitants of Auroria were a peaceful and harmonious race known as the Lumarians, who possessed incredible powers of light and healing.\\n\\nHowever, this tranquility was threatened by the dark forces of the Shadow Empire, led by the sinister warlord Malakar. Malakar desired to harness the Lumarians' powers for his own nefarious purposes and enslave them under\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse.decorators import observe\n",
    "from langfuse.openai import openai # OpenAI integration\n",
    " \n",
    "@observe()\n",
    "def story():\n",
    "    return openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=100,\n",
    "        messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are a great storyteller.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Once upon a time in a galaxy far, far away...\"}\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    " \n",
    "@observe()\n",
    "def main():\n",
    "    return story()\n",
    " \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22ad1f79-0571-429b-a46f-c364254799e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse.create_dataset(name=\"capital_cities\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2f34d74-0c0a-4776-a29a-99243d4b49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example items, could also be json instead of strings\n",
    "local_items = [\n",
    "    {\"input\": {\"country\": \"Italy\"}, \"expected_output\": \"Rome\"},\n",
    "    {\"input\": {\"country\": \"Spain\"}, \"expected_output\": \"Madrid\"},\n",
    "    {\"input\": {\"country\": \"Brazil\"}, \"expected_output\": \"Brasília\"},\n",
    "    {\"input\": {\"country\": \"Japan\"}, \"expected_output\": \"Tokyo\"},\n",
    "    {\"input\": {\"country\": \"India\"}, \"expected_output\": \"New Delhi\"},\n",
    "    {\"input\": {\"country\": \"Canada\"}, \"expected_output\": \"Ottawa\"},\n",
    "    {\"input\": {\"country\": \"South Korea\"}, \"expected_output\": \"Seoul\"},\n",
    "    {\"input\": {\"country\": \"Argentina\"}, \"expected_output\": \"Buenos Aires\"},\n",
    "    {\"input\": {\"country\": \"South Africa\"}, \"expected_output\": \"Pretoria\"},\n",
    "    {\"input\": {\"country\": \"Egypt\"}, \"expected_output\": \"Cairo\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c70581af-32a5-4266-a34a-ee271bb3dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to Langfuse\n",
    "for item in local_items:\n",
    "  langfuse.create_dataset_item(\n",
    "      dataset_name=\"capital_cities\",\n",
    "      # any python object or value\n",
    "      input=item[\"input\"],\n",
    "      # any python object or value, optional\n",
    "      expected_output=item[\"expected_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48aaf636-7c8a-4735-b4be-47b2c7dabb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.openai import openai\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    " \n",
    "@observe()\n",
    "def run_my_custom_llm_app(input, system_prompt):\n",
    "  messages = [\n",
    "      {\"role\":\"system\", \"content\": system_prompt},\n",
    "      {\"role\":\"user\", \"content\": input[\"country\"]}\n",
    "  ]\n",
    " \n",
    "  completion = openai.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=messages\n",
    "  ).choices[0].message.content\n",
    " \n",
    "  return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2066817f-db70-49ef-9f78-c5a63cd9b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a very simple eval here, you can use any eval library\n",
    "# see https://langfuse.com/docs/scores/model-based-evals for details\n",
    "# you can also use LLM-as-a-judge managed within Langfuse to evaluate the outputs\n",
    "def simple_evaluation(output, expected_output):\n",
    "  return output == expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c1f3924-37ab-4dba-bb45-1f523d341c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name, system_prompt):\n",
    "  dataset = langfuse.get_dataset(\"capital_cities\")\n",
    " \n",
    "  for item in dataset.items:\n",
    "    # item.observe() returns a trace_id that can be used to add custom evaluations later\n",
    "    # it also automatically links the trace to the experiment run\n",
    "    with item.observe(run_name=experiment_name) as trace_id:\n",
    " \n",
    "      # run application, pass input and system prompt\n",
    "      output = run_my_custom_llm_app(item.input, system_prompt)\n",
    " \n",
    "      # optional: add custom evaluation results to the experiment trace\n",
    "      # we use the previously created example evaluation function\n",
    "      langfuse.score(\n",
    "        trace_id=trace_id,\n",
    "        name=\"exact_match\",\n",
    "        value=simple_evaluation(output, item.expected_output)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93586506-3696-4fde-92a8-2564a95e63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context\n",
    " \n",
    "run_experiment(\n",
    "    \"famous_city\",\n",
    "    \"The user will input countries, respond with the most famous city in this country\"\n",
    ")\n",
    "run_experiment(\n",
    "    \"directly_ask\",\n",
    "    \"What is the capital of the following country?\"\n",
    ")\n",
    "run_experiment(\n",
    "    \"asking_specifically\",\n",
    "    \"The user will input countries, respond with only the name of the capital\"\n",
    ")\n",
    "run_experiment(\n",
    "    \"asking_specifically_2nd_try\",\n",
    "    \"The user will input countries, respond with only the name of the capital. State only the name of the city.\"\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e4712bf-2a80-42cf-ade6-273eb162d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer paid with card number 4111 1111 1111 1111.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langfuse.decorators import langfuse_context, observe\n",
    " \n",
    "# Step 2: Define the masking function\n",
    "def masking_function(data):\n",
    "    if isinstance(data, str):\n",
    "        # Regular expression to match credit card numbers (Visa, MasterCard, AmEx, etc.)\n",
    "        pattern = r'\\b(?:\\d[ -]*?){13,19}\\b'\n",
    "        data = re.sub(pattern, '[REDACTED CREDIT CARD]', data)\n",
    "    return data\n",
    " \n",
    "# Step 3: Configure the masking function\n",
    "langfuse_context.configure(mask=masking_function)\n",
    " \n",
    "# Step 4: Create a sample function with sensitive data\n",
    "@observe()\n",
    "def process_payment():\n",
    "    # Simulated sensitive data containing a credit card number\n",
    "    transaction_info = \"Customer paid with card number 4111 1111 1111 1111.\"\n",
    "    return transaction_info\n",
    " \n",
    "# Step 5: Observe the trace\n",
    "result = process_payment()\n",
    " \n",
    "print(result)\n",
    "# Output: Customer paid with card number [REDACTED CREDIT CARD]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66532cae-785d-45a2-a72f-2929f861a906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
