{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyaneshhere/LLM-Security-and-Observability/blob/main/LangFuse/Develop/Prompt%20Management/prompt_management_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atFOx9Rh6rae"
      },
      "source": [
        "---\n",
        "description: Example of Open Source Prompt Management for Langchain applications using Langfuse.\n",
        "category: Prompt Management\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc7JQAashNea"
      },
      "source": [
        "# Example: Langfuse Prompt Management with Langchain (Python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qGbaVDEiK6o"
      },
      "source": [
        "[Langfuse Prompt Management](https://langfuse.com/docs/prompts) helps to version control and manage prompts collaboratively in one place. This example demostrates how to use prompts managed in Langchain applications.\n",
        "\n",
        "_In addition, we use [Langfuse Tracing](https://langfuse.com/docs/tracing) via the native [Langchain integration](https://langfuse.com/docs/integrations/langchain) to inspect and debug the Langchain application._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwyrmsWZhsFW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJzIBAVKKdoD",
        "outputId": "95da50d2-9d41-4e3e-e8bf-cc6f83c6bd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse\n",
            "  Downloading langfuse-2.60.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from langfuse) (4.9.0)\n",
            "Collecting backoff>=1.10.0 (from langfuse)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from langfuse) (0.28.1)\n",
            "Requirement already satisfied: idna<4.0,>=3.7 in /usr/local/lib/python3.11/dist-packages (from langfuse) (3.10)\n",
            "Requirement already satisfied: packaging<25.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langfuse) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.11/dist-packages (from langfuse) (2.11.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langfuse) (2.32.3)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.11/dist-packages (from langfuse) (1.17.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.75.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.4.0->langfuse) (4.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langfuse) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langfuse) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Downloading langfuse-2.60.3-py3-none-any.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.0/275.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: backoff, tiktoken, langfuse, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.52\n",
            "    Uninstalling langchain-core-0.3.52:\n",
            "      Successfully uninstalled langchain-core-0.3.52\n",
            "Successfully installed backoff-2.2.1 langchain-core-0.3.55 langchain-openai-0.3.14 langfuse-2.60.3 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse langchain langchain-openai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "a5ktHUBO6vzJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_f8m2HYAKfJz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# get keys for your project from https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get('LANGFUSE_PUBLIC_KEY')\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get('LANGFUSE_SECRET_KEY')\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"\n",
        "\n",
        "# your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0ABMEWVCKsPW"
      },
      "outputs": [],
      "source": [
        "from langfuse import Langfuse\n",
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "# Initialize Langfuse client (prompt management)\n",
        "langfuse = Langfuse()\n",
        "\n",
        "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
        "langfuse_callback_handler = CallbackHandler()\n",
        "\n",
        "# Optional, verify that Langfuse is configured correctly\n",
        "assert langfuse.auth_check()\n",
        "assert langfuse_callback_handler.auth_check()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHpmb6vLAiW"
      },
      "source": [
        "## Add prompt to Langfuse Prompt Management\n",
        "\n",
        "We add the prompt used in this example via the SDK. Alternatively, you can also edit and version the prompt in the Langfuse UI.\n",
        "\n",
        "- `Name` that identifies the prompt in Langfuse Prompt Management\n",
        "- Prompt with prompt template incl. `{{input variables}}`\n",
        "- Config including `model_name` and `temperature`\n",
        "- `labels` to include `production` to immediately use prompt as the default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pX54t3k0gM5w"
      },
      "outputs": [],
      "source": [
        "langfuse.create_prompt(\n",
        "    name=\"event-planner\",\n",
        "    prompt=\n",
        "    \"Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. \"\n",
        "    \"The event will be held in {{Location}} on {{Date}}. \"\n",
        "    \"Consider the following factors: audience, budget, venue, catering options, and entertainment. \"\n",
        "    \"Provide a detailed plan including potential vendors and logistics.\",\n",
        "    config={\n",
        "        \"model\":\"gpt-4o\",\n",
        "        \"temperature\": 0,\n",
        "    },\n",
        "    labels=[\"production\"]\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg-u-v_N6ral"
      },
      "source": [
        "Prompt in Langfuse UI\n",
        "\n",
        "![Created prompt in Langfuse UI](https://langfuse.com/images/docs/prompt-management-langchain-prompt.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6RkSjUx6ram"
      },
      "source": [
        "## Example application\n",
        "\n",
        "### Get current prompt version from Langfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pBt5frgJ6ram"
      },
      "outputs": [],
      "source": [
        "# Get current production version of prompt\n",
        "langfuse_prompt = langfuse.get_prompt(\"event-planner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFdbHvYz6ram"
      },
      "source": [
        "```python\n",
        "print(langfuse_prompt.prompt)\n",
        "```\n",
        "\n",
        "```\n",
        "Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. The event will be held in {{Location}} on {{Date}}. Consider the following factors: audience, budget, venue, catering options, and entertainment. Provide a detailed plan including potential vendors and logistics.\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(langfuse_prompt.prompt)"
      ],
      "metadata": {
        "id": "m0oSlthn7jtz",
        "outputId": "4fb77e95-c55d-46c0-9726-0b2f4f07008e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan an event titled {{Event Name}}. The event will be about: {{Event Description}}. The event will be held in {{Location}} on {{Date}}. Consider the following factors: audience, budget, venue, catering options, and entertainment. Provide a detailed plan including potential vendors and logistics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahvMYvS1RsF9"
      },
      "source": [
        "### Transform into Langchain PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQwfPI42IZM0"
      },
      "source": [
        "Use the utility method `.get_langchain_prompt()` to transform the Langfuse prompt into a string that can be used in Langchain.\n",
        "\n",
        "Context: Langfuse declares input variables in prompt templates using double brackets (`{{input variable}}`). Langchain uses single brackets for declaring input variables in PromptTemplates (`{input variable}`). The utility method `.get_langchain_prompt()` replaces the double brackets with single brackets.\n",
        "\n",
        "Also, pass the Langfuse prompt as metadata to the PromptTemplate to automatically link generations that use the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W0PHfX_QMWHM"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "langchain_prompt = ChatPromptTemplate.from_template(\n",
        "        langfuse_prompt.get_langchain_prompt(),\n",
        "        metadata={\"langfuse_prompt\": langfuse_prompt},\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZWWnEVyN9AK"
      },
      "source": [
        "Extract the configuration options from `prompt.config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4FNbRwROCab",
        "outputId": "9915d095-aa86-4655-cb8f-e14e65f0c291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt model configurations\n",
            "Model: gpt-4o\n",
            "Temperature: 0\n"
          ]
        }
      ],
      "source": [
        "model = langfuse_prompt.config[\"model\"]\n",
        "temperature = str(langfuse_prompt.config[\"temperature\"])\n",
        "print(f\"Prompt model configurations\\nModel: {model}\\nTemperature: {temperature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGCZnwK4CI31"
      },
      "source": [
        "### Create Langchain chain based on prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Phi3qcusC0Aa"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=model, temperature=temperature)\n",
        "\n",
        "chain = langchain_prompt | model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEzzzavik9g8"
      },
      "source": [
        "## Invoke chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZL1WzXTE6rao"
      },
      "outputs": [],
      "source": [
        "example_input = {\n",
        "    \"Event Name\": \"Wedding\",\n",
        "    \"Event Description\": \"The wedding of Julia and Alex, a charming couple who share a love for art and nature. This special day will celebrate their journey together with a blend of traditional and contemporary elements, reflecting their unique personalities.\",\n",
        "    \"Location\": \"Central Park, New York City\",\n",
        "    \"Date\": \"June 5, 2024\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZVE_F_8WELq",
        "outputId": "5d8b7a8d-37c7-4257-d3f2-46b1556f51f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To plan an event titled \"Green Future Festival,\" which focuses on sustainability, environmental awareness, and green technology, we will consider the following factors: audience, budget, venue, catering options, and entertainment. The event will be held in Central Park, New York City, on June 5, 2024.\n",
            "\n",
            "### Event Overview\n",
            "**Event Name:** Green Future Festival  \n",
            "**Event Date:** June 5, 2024  \n",
            "**Location:** Central Park, New York City  \n",
            "**Event Description:** A day-long festival celebrating sustainability, featuring workshops, panel discussions, eco-friendly vendors, and live entertainment to promote environmental awareness and green technology.\n",
            "\n",
            "### Audience\n",
            "- **Target Audience:** Environmentally conscious individuals, families, students, professionals in green industries, and local community members.\n",
            "- **Expected Attendance:** 5,000 - 7,000 people.\n",
            "\n",
            "### Budget\n",
            "- **Estimated Budget:** $150,000\n",
            "  - Venue and Permits: $20,000\n",
            "  - Catering: $30,000\n",
            "  - Entertainment: $40,000\n",
            "  - Marketing and Promotion: $20,000\n",
            "  - Logistics and Operations: $25,000\n",
            "  - Miscellaneous (decor, insurance, etc.): $15,000\n",
            "\n",
            "### Venue\n",
            "- **Location:** Central Park, New York City\n",
            "- **Permits:** Obtain necessary permits from NYC Parks Department for event space, sound, and any temporary structures.\n",
            "- **Layout:** Designate areas for workshops, vendor booths, food stalls, and a main stage for entertainment.\n",
            "\n",
            "### Catering Options\n",
            "- **Vendors:** Partner with local, sustainable catering companies and food trucks that offer organic, plant-based, and locally sourced options.\n",
            "  - **Potential Vendors:**\n",
            "    - The Cinnamon Snail (vegan food truck)\n",
            "    - Van Leeuwen Ice Cream (vegan options)\n",
            "    - Dig Inn (farm-to-table meals)\n",
            "- **Beverages:** Provide water refill stations to minimize plastic waste and partner with eco-friendly beverage companies.\n",
            "\n",
            "### Entertainment\n",
            "- **Main Stage Performances:** Schedule live music from eco-conscious artists and bands.\n",
            "  - **Potential Artists:** Jack Johnson, Michael Franti, or local indie bands.\n",
            "- **Workshops and Panels:** Host sessions on topics like renewable energy, sustainable living, and green technology innovations.\n",
            "  - **Speakers:** Invite environmental activists, scientists, and industry leaders.\n",
            "- **Activities:** Include interactive activities such as a community art project using recycled materials and a kids' zone with educational games.\n",
            "\n",
            "### Logistics\n",
            "- **Transportation:** Encourage public transportation, biking, and carpooling. Provide bike racks and partner with local transit for discounts.\n",
            "- **Waste Management:** Implement a zero-waste policy with recycling and composting stations. Partner with a waste management company like TerraCycle.\n",
            "- **Security and Safety:** Hire a security team and coordinate with local authorities for crowd control and emergency services.\n",
            "- **Volunteers:** Recruit volunteers for event setup, information booths, and cleanup efforts.\n",
            "\n",
            "### Marketing and Promotion\n",
            "- **Strategy:** Utilize social media, local press, and partnerships with environmental organizations to promote the event.\n",
            "- **Materials:** Create digital flyers, posters, and a dedicated event website with registration details.\n",
            "- **Partnerships:** Collaborate with local schools, universities, and environmental groups for outreach.\n",
            "\n",
            "### Potential Vendors and Partners\n",
            "- **Eco-Friendly Vendors:** Reach out to local businesses that align with the event's sustainability theme for vendor booths.\n",
            "- **Sponsors:** Seek sponsorship from companies in the renewable energy sector, sustainable fashion, and eco-friendly products.\n",
            "\n",
            "By focusing on these elements, the Green Future Festival aims to create an engaging and educational experience that inspires attendees to adopt more sustainable practices in their daily lives.\n"
          ]
        }
      ],
      "source": [
        "# we pass the callback handler to the chain to trace the run in Langfuse\n",
        "response = chain.invoke(input=example_input,config={\"callbacks\":[langfuse_callback_handler]})\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQlOxtZGhKN7"
      },
      "source": [
        "## View Trace in Langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFBmiR-agkb7"
      },
      "source": [
        "Now we can see that the trace incl. the prompt template have been logged to Langfuse\n",
        "\n",
        "![Trace of prompt used in Langchain in Langfuse](https://langfuse.com/images/docs/prompt-management-langchain-trace.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD6C146mjCsF"
      },
      "source": [
        "## Iterate on prompt in Langfuse\n",
        "We can now continue adapting our prompt template in the Langfuse UI and continuously update the prompt template in our Langchain application via the script above."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}