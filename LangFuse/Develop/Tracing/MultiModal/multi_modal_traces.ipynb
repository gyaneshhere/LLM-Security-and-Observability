{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyaneshhere/LLM-Security-and-Observability/blob/main/LangFuse/Develop/Tracing/MultiModal/multi_modal_traces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84VgoFmfIOlC"
      },
      "source": [
        "---\n",
        "category: Examples\n",
        "description: Examples of how to use multi-modality and attachments with the Langfuse Python SDK.\n",
        "---\n",
        "\n",
        "# Example: Multi-modality and attachments\n",
        "\n",
        "These are examples of how to use multi-modality and attachments with the Langfuse Python SDK.\n",
        "\n",
        "See the [multi-modality documentation](https://langfuse.com/docs/tracing-features/multi-modality) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfzgOPYd5hl0"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5MlvUWG5jW3",
        "outputId": "46eef440-e2f6-4544-af99-bcb43ae30db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse\n",
            "  Downloading langfuse-2.60.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from langfuse) (4.9.0)\n",
            "Collecting backoff>=1.10.0 (from langfuse)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from langfuse) (0.28.1)\n",
            "Requirement already satisfied: idna<4.0,>=3.7 in /usr/local/lib/python3.11/dist-packages (from langfuse) (3.10)\n",
            "Requirement already satisfied: packaging<25.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langfuse) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.11/dist-packages (from langfuse) (2.11.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langfuse) (2.32.3)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.11/dist-packages (from langfuse) (1.17.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.75.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.4.0->langfuse) (4.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langfuse) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langfuse) (2.3.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Downloading langfuse-2.60.3-py3-none-any.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.0/275.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: backoff, tiktoken, langfuse, langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.52\n",
            "    Uninstalling langchain-core-0.3.52:\n",
            "      Successfully uninstalled langchain-core-0.3.52\n",
            "Successfully installed backoff-2.2.1 langchain-core-0.3.54 langchain_openai-0.3.14 langfuse-2.60.3 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langfuse langchain langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YELrcpJe6ERT",
        "outputId": "44519e79-7e3c-4c1c-d812-78b1da93ee60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded: puton.jpg\n",
            "Successfully downloaded: joke_prompt.wav\n",
            "Successfully downloaded: bitcoin.pdf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "from urllib.error import URLError\n",
        "\n",
        "REPO_URL = \"https://github.com/langfuse/langfuse-python\"\n",
        "download_path = \"static\"\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "test_files = [\"puton.jpg\", \"joke_prompt.wav\", \"bitcoin.pdf\"]\n",
        "raw_url = f\"{REPO_URL}/raw/main/{download_path}\"\n",
        "\n",
        "for file in test_files:\n",
        "   try:\n",
        "       urlretrieve(f\"{raw_url}/{file}\", f\"{download_path}/{file}\")\n",
        "       print(f\"Successfully downloaded: {file}\")\n",
        "   except URLError as e:\n",
        "       print(f\"Failed to download {file}: {e}\")\n",
        "   except OSError as e:\n",
        "       print(f\"Failed to save {file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "XcLNvqBFYfkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Nv_oJg070vo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get keys for your project from the project settings page\n",
        "# https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get('LANGFUSE_PUBLIC_KEY')\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get('LANGFUSE_SECRET_KEY')\n",
        "#os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # 🇪🇺 EU region\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # 🇺🇸 US region\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2GoBv_b5hl2"
      },
      "outputs": [],
      "source": [
        "from langfuse.openai import openai\n",
        "import base64\n",
        "\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def encode_file(image_path):\n",
        "    with open(image_path, \"rb\") as file:\n",
        "        return base64.b64encode(file.read()).decode(\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny5aDV3C5hl3"
      },
      "source": [
        "## OpenAI SDK: Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLRwIucQ5hl3",
        "outputId": "113c0020-7122-47f1-a0ed-e1d807beb901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'chatcmpl-BOGKvJzJm1MlKjSOJMDF5f4U65BpK', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The image appears to show a dog with curly fur, likely sitting with its front paws resting on a person's knee. The dog's expression looks friendly, with its tongue out and a happy demeanor. In the background, there seem to be people standing, but they are not the focus of the image. The setting appears to be indoors, with wooden flooring and a colorful rug.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], 'created': 1745122369, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_f7d56a8a2c', 'usage': CompletionUsage(completion_tokens=75, prompt_tokens=25514, total_tokens=25589, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), '_request_id': 'req_55c4c38c03ad84a0c075e7b42589c031'}\n"
          ]
        }
      ],
      "source": [
        "content_path = \"static/puton.jpg\"\n",
        "content_type = \"image/jpeg\"\n",
        "\n",
        "base64_image = encode_file(content_path)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:{content_type};base64,{base64_image}\"\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.__dict__)\n",
        "\n",
        "openai.flush_langfuse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bOH7D-e5hl3"
      },
      "source": [
        "## OpenAI SDK: Audio input and output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdnPcy7A5hl4",
        "outputId": "7acd8866-954e-401c-8c78-39f83232c5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'chatcmpl-BOGL568tBmA2ww5Rl8KIEDV7K2tfA', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=ChatCompletionAudio(id='audio_6804744cfa4c81918584b5894676197b', data=<langfuse.media.LangfuseMedia object at 0x7cb789ed8790>, expires_at=1745125980, transcript='Why did the hipster burn his mouth in Berlin? Because he ate the currywurst before it was cool!'), function_call=None, tool_calls=None))], 'created': 1745122379, 'model': 'gpt-4o-audio-preview-2024-12-17', 'object': 'chat.completion', 'service_tier': 'default', 'system_fingerprint': 'fp_bf4a46b2e5', 'usage': CompletionUsage(completion_tokens=184, prompt_tokens=66, total_tokens=250, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=147, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=37), prompt_tokens_details=PromptTokensDetails(audio_tokens=49, cached_tokens=0, text_tokens=17, image_tokens=0)), '_request_id': 'req_a89d587563c6a33365ab48a861449831'}\n"
          ]
        }
      ],
      "source": [
        "content_path = \"static/joke_prompt.wav\"\n",
        "\n",
        "base64_string = encode_file(content_path)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-audio-preview\",\n",
        "    modalities=[\"text\", \"audio\"],\n",
        "    audio={\"voice\": \"alloy\", \"format\": \"wav\"},\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"Do what this recording says.\"},\n",
        "                {\n",
        "                    \"type\": \"input_audio\",\n",
        "                    \"input_audio\": {\"data\": base64_string, \"format\": \"wav\"},\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.__dict__)\n",
        "\n",
        "openai.flush_langfuse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-3J5QWO5hl5"
      },
      "source": [
        "## Python Decorator: Attachments via `LangfuseMedia`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uqx4AyV5hl5"
      },
      "outputs": [],
      "source": [
        "from langfuse.decorators import observe, langfuse_context\n",
        "from langfuse.media import LangfuseMedia\n",
        "\n",
        "with open(\"static/bitcoin.pdf\", \"rb\") as pdf_file:\n",
        "        pdf_bytes = pdf_file.read()\n",
        "\n",
        "wrapped_obj = LangfuseMedia(\n",
        "    obj=pdf_bytes, content_bytes=pdf_bytes, content_type=\"application/pdf\"\n",
        ")\n",
        "\n",
        "@observe()\n",
        "def main():\n",
        "    langfuse_context.update_current_trace(\n",
        "        metadata={\n",
        "            \"context\": wrapped_obj\n",
        "        },\n",
        "    )\n",
        "\n",
        "    return # Limitation: LangfuseMedia object does not work in decorated function IO\n",
        "\n",
        "main()\n",
        "\n",
        "langfuse_context.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0XObJp45hl6"
      },
      "source": [
        "## Langchain: Image input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAcMjZa55hl6",
        "outputId": "b09a6eae-b5eb-4918-a9bb-435c20a6073c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image features a fluffy dog with a curly coat, sitting and resting its front paws on a person's knee. The dog appears to be happy, with its tongue out. In the background, there are a few people standing, and some household items are visible, indicating a cozy indoor setting. The floor is hardwood, and there’s a patterned rug beneath the dog.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "from langfuse.callback import CallbackHandler\n",
        "\n",
        "handler = CallbackHandler()\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "image_data = encode_file(\"static/puton.jpg\")\n",
        "\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "response = model.invoke([message], config={\"callbacks\": [handler]})\n",
        "\n",
        "print(response.content)\n",
        "\n",
        "handler.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUrNuDuG-ZUv"
      },
      "source": [
        "## Custom via API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XTiq2xrYN3z"
      },
      "source": [
        "[Link to API docs](https://api.reference.langfuse.com/#tag--Media)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz-ucrLcBJXh"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcF2TiyP-cOD",
        "outputId": "a13dc2b3-4ed1-4182-c5c6-388db5dadee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'traceId': '8c17d342-d6a0-4461-b2dc-47592562556b',\n",
              " 'contentType': 'image/jpeg',\n",
              " 'contentLength': 650780,\n",
              " 'sha256Hash': 'i5BuV2qX9nPaAAPf7c0gCYPLPU2GS3VUFKctrbzTKu4=',\n",
              " 'field': 'input'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import base64\n",
        "import hashlib\n",
        "import uuid\n",
        "\n",
        "base_URL = os.getenv(\"LANGFUSE_HOST\")\n",
        "public_key = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
        "secret_key = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
        "\n",
        "file_path = \"static/puton.jpg\"\n",
        "\n",
        "with open(file_path, \"rb\") as f:\n",
        "    content_bytes = f.read()\n",
        "\n",
        "content_type = \"image/jpeg\"\n",
        "content_sha256 = base64.b64encode(hashlib.sha256(content_bytes).digest()).decode()\n",
        "trace_id = str(uuid.uuid4())\n",
        "content_length = len(content_bytes)\n",
        "field = \"input\"  # or \"output\" or \"metadata\"\n",
        "\n",
        "create_upload_url_body = {\n",
        "    \"traceId\": trace_id,\n",
        "    \"contentType\": content_type,\n",
        "    \"contentLength\": content_length,\n",
        "    \"sha256Hash\": content_sha256,\n",
        "    \"field\": field,\n",
        "}\n",
        "\n",
        "create_upload_url_body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj4lXSrIBLvO"
      },
      "source": [
        "### Get upload URL and media ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsO2H9F8Bbat",
        "outputId": "f242efca-79b1-46c2-8c1e-895799481bc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mediaId': 'iLW3oIHaOLi0l70awEz1iW', 'uploadUrl': None}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "upload_url_request = requests.post(\n",
        "    f\"{base_URL}/api/public/media\",\n",
        "    auth=(public_key or \"\", secret_key or \"\"),\n",
        "    headers={\"Content-Type\": \"application/json\"},\n",
        "    json=create_upload_url_body,\n",
        ")\n",
        "\n",
        "upload_url_response = upload_url_request.json()\n",
        "upload_url_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-1bOc-FJHoO"
      },
      "source": [
        "Note: `uploadUrl` is `None` if the file is stored in Langfuse already as then there is no need to upload it again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2LjvnPECl2Z"
      },
      "source": [
        "### Upload file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2phMRncCoEi"
      },
      "outputs": [],
      "source": [
        "# If there is no uploadUrl, file was already uploaded\n",
        "if (upload_url_response[\"mediaId\"] is not None and upload_url_response[\"uploadUrl\"] is not None):\n",
        "    upload_response = requests.put(\n",
        "        upload_url_response[\"uploadUrl\"],\n",
        "        headers={\n",
        "            \"Content-Type\": content_type,\n",
        "            \"x-amz-checksum-sha256\": content_sha256,\n",
        "        },\n",
        "        data=content_bytes,\n",
        "    )\n",
        "\n",
        "    print(\"File uploaded\")\n",
        "    print(upload_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg5V6la9YN30"
      },
      "source": [
        "### Update upload status"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "# Check if upload_response exists and has a value before proceeding\n",
        "if 'upload_response' in locals() and upload_response is not None:\n",
        "    requests.patch(\n",
        "        f\"{base_URL}/api/public/media/{upload_url_response['mediaId']}\",\n",
        "        auth=(public_key or \"\", secret_key or \"\"),\n",
        "        headers={\"Content-Type\": \"application/json\"},\n",
        "        json={\n",
        "            \"uploadedAt\": datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%fZ'), # ISO 8601\n",
        "            \"uploadHttpStatus\": upload_response.status_code,\n",
        "            \"uploadHttpError\": upload_response.text if upload_response.status_code != 200 else None,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    print(\"Upload status updated\")\n",
        "else:\n",
        "    print(\"Skipping upload status update as upload_response is not available.\") # Add a helpful message"
      ],
      "metadata": {
        "id": "YfnOaDphalgH",
        "outputId": "0c0a8a1d-cc23-4dcb-b223-382aee8c41a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping upload status update as upload_response is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx6WCkXUDwsf"
      },
      "source": [
        "### Fetch media link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4ovrokHDztK",
        "outputId": "98676873-253d-4386-c563-0a45ac75741a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mediaId': 'iLW3oIHaOLi0l70awEz1iW',\n",
              " 'contentType': 'image/jpeg',\n",
              " 'contentLength': 650780,\n",
              " 'url': 'https://langfuse-prod-us-media.s3.us-west-2.amazonaws.com/cm6lmc14y022zvate2r5eb0xy/iLW3oIHaOLi0l70awEz1iW.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIA5FCD6K7QWCMUVN6F%2F20250420%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250420T041756Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEA8aCXVzLXdlc3QtMiJGMEQCIE%2BsKOshxGwuecgp3EkX6XitsWUvAOICv6MALKnPwJBkAiBj%2FNKB%2FOAdP6QrRElJvMUoXzcbwrUtc38e30dZvwt3BSr%2BAwiY%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDkwNDIzMzExMzU2OSIMGvYstZi2%2F7GxZAFdKtIDSOM%2FUd9TP7GCOm1A3MmWrFuy68V4xeudnmgYZkosVfzLxGtUpxqPIPpUkP9%2BuChOUnXr%2Fzl7U5j7tZNVV9NVtN%2B5rrSkUReBOVruPNmJoCXwNw91YM5bW2GOwv6xgXXAarZRhxuixj5yvzUJ80SipfGI9BhxnnzJO5FbpB6u8UMiSysnoV4bDrO3qlh4335bh9h8X1d0iUAYxqHCAh5R%2Foouk4U7GNkGhF2NpTACXuNwI1uNvjEfZArr7N3JUbmwy0ttsGWUkRJhI9IJItpZ63mZALhdr5lwyLmtWCeQEeNzHDNzkgD11j%2BoHeEfD3i72W4%2B3D6RM8FpYhc6Kq1ce2Di3%2Fz6UmaKUrcmW3fOWUY7tLoIX6Hoht4jyiUlYliIxTuE%2FileanthKdNelbxINwU0%2BAQNKhHmVUe%2FkQ2h1Rmfulsrb35cN7iT5KAveAxjyPPycsOg%2F1e4Z4pAwWgukiVN9v7052whypxRGuW3yG6YyENcouMygDpvd4aDe13SAF5JsZho3%2FGluFk15sANCV8JOXCJ8hMmfcqYKHjK8dKmIxTKFSQ2svGljtrCYJ1j5S4wsnfalO%2FDrp%2FXQmvlvTcvW%2BAqtWHP5QQ25x2GOEvYjDDZ25DABjqmAX2Qha1rtJE1WOqsGVEiOzDxreA4V1so4tB8%2B0kMgEdBbOMStMxfCcXbrf4FZF3xLLE3ztN1lWZwkHKaCjUWy6c4DKWL8WzlO2ww9HZRsJdJFtRpGkm3MdVOSvlFh0w6x6R2vI3GEm4cCMB5qU89ItybdVP5%2FagUmTYh49ws5TtzsleF3kP4M5jrU%2F7NU2UjGQCa4VA3n9Yv3LjZYTn8g%2FuWePohT0Q%3D&X-Amz-Signature=a8e8d17471065427c4c0d948e747cc6e2786f7fa2d0a8af4b96194c8bc3391e5&X-Amz-SignedHeaders=host&x-id=GetObject',\n",
              " 'urlExpiry': '2025-04-20T05:17:56.342Z',\n",
              " 'uploadedAt': '2025-04-20T04:12:51.518Z'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "media_request = requests.get(\n",
        "    f\"{base_URL}/api/public/media/{upload_url_response['mediaId']}\",\n",
        "    auth=(public_key or \"\", secret_key or \"\")\n",
        ")\n",
        "\n",
        "media_response = media_request.json()\n",
        "media_response\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "langfuse-wN49ODZY-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}